# A/B Testing

# Multi-Armed Bandit (MAB) Problem Simulation and Comparison

This repository contains a Python implementation of two algorithms for solving the Multi-Armed Bandit (MAB) problem: Epsilon Greedy and Thompson Sampling. The MAB problem is a classic problem in statistics and machine learning, involving a trade-off between exploring different options (arms) to find the best one and exploiting the currently best-known option.

## Table of Contents

- [Overview](#overview)
- [File Structure](#file-structure)
- [Results and Visualization](#results-and-visualization)
- [Author](#author)

## Overview

The repository is organized as follows:

- `bandits.py`: Contains the implementation of the Epsilon Greedy and Thompson Sampling bandit algorithms.
- `visualization.py`: Provides visualization and comparison of the algorithms' performance.
- `main.py`: Demonstrates how to use the bandit algorithms and visualize the results.
- `README.md`: This file, providing an overview of the project.

The main goal of this project is to compare the performance of Epsilon Greedy and Thompson Sampling algorithms in solving the Multi-Armed Bandit problem. Both algorithms are implemented as classes, allowing you to create bandits with different reward distributions and experiment with various parameters.

## File Structure

The project's file structure is as follows:

bandits.py: Contains the bandit classes.
visualization.py: Provides visualization functions.
main.py: The main script to run the experiments.
README.md: The readme file.
Other files and data generated during experiments.

## Results and Visualization

The results of the experiments, including reward data, comparisons, and visualizations, will be saved in CSV files and displayed in the script output. You can analyze the generated data to understand the performance of each algorithm.

## Author

Yeva Avetisyan


```python

```
